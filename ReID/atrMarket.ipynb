{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "#get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '../../'\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "import fileinput\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Net(sys.argv[1], #path to deploy prototxt,\n",
    "                sys.argv[2], #path to learned model,\n",
    "                caffe.TEST)# input preprocessing: 'data'is the name of the input blob == net.inputs[0]\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "#transformer.set_mean('data', np.load(caffe_root + 'rank_scripts/query_128x128_market.npy').mean(1).mean(1)) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "image_data = []\n",
    "label = []\n",
    "attributes = []\n",
    "#******************************\n",
    "#Forward Pass for  Test Folder\n",
    "#******************************\n",
    "test_folder = '/users/gpu/agjayant1/Market-1501-v15.09.15/bounding_box_trainx2/'\n",
    "# test_folder = '/users/gpu/agjayant1/Market-1501-v15.09.15/query/'\n",
    "images_list = os.listdir(test_folder)\n",
    "\n",
    "print \"Setup Done. Starting Forward Pass for Test Images\"\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "num_images = len(images_list)\n",
    "BatchSize = 100\n",
    "j=0\n",
    "\n",
    "while j < 5000:\n",
    "    net = caffe.Net(sys.argv[1], # deploy prototxt,\n",
    "                sys.argv[2], # model,\n",
    "                caffe.TEST)# input preprocessing: 'data'is the name of the input blob == net.inputs[0]\n",
    "\n",
    "\n",
    "    # set net to batch size\n",
    "    net.blobs['data'].reshape(BatchSize,3,227,227)\n",
    "    i = 0\n",
    "    k = j\n",
    "    while j < num_images and i < BatchSize:\n",
    "        test_image = caffe.io.load_image(test_folder+ images_list[j])\n",
    "        net.blobs['data'].data[i] = transformer.preprocess('data', test_image)\n",
    "        i = i + 1\n",
    "        j = j + 1\n",
    "\n",
    "    out = net.forward()\n",
    "    i=0\n",
    "    while k < num_images and i < BatchSize:\n",
    "        pic = Image.open(test_folder+images_list[k])\n",
    "        A = np.array(pic,dtype='f4')\n",
    "        A = A.transpose((2,0,1))\n",
    "        image_data.append(A)\n",
    "        a = out['fc8_a'][i]\n",
    "        b =  sorted(range(len(a)), key=lambda x: a[x])[-20:]\n",
    "        d = [0] * 106\n",
    "        D= np.array(d)\n",
    "        D[b] = 1\n",
    "        attributes.append(D)\n",
    "        label.append(int(item.split('_')[0]))\n",
    "        i = i + 1\n",
    "        k = k + 1\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "print \"**************************************************\"\n",
    "print \"Forward Pass Completed for all Test Images: Part 1\"\n",
    "print \"**************************************************\"\n",
    "label = np.array(label,dtype='f4')\n",
    "attributes = np.array(attributes,dtype='f4')\n",
    "h = h5py.File(\"/users/gpu/agjayant/Market-1501-v15.09.15/market_training1.h5\", 'w' )\n",
    "dset1 = h.create_dataset(\"data\", data=image_data)\n",
    "dset2 = h.create_dataset(\"attributes\", data=attributes)\n",
    "dset3 = h.create_dataset(\"label\",  data=label)\n",
    "h.close()\n",
    "\n",
    "print \"**************************************************\"\n",
    "print \"Saved for all Images: Part 1\"\n",
    "print \"**************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "label = []\n",
    "attributes = []\n",
    "while j < 10000:\n",
    "    net = caffe.Net(sys.argv[1], # deploy prototxt,\n",
    "                sys.argv[2], # model,\n",
    "                caffe.TEST)# input preprocessing: 'data'is the name of the input blob == net.inputs[0]\n",
    "\n",
    "\n",
    "    # set net to batch size\n",
    "    net.blobs['data'].reshape(BatchSize,3,227,227)\n",
    "    i = 0\n",
    "    k = j\n",
    "    while j < num_images and i < BatchSize:\n",
    "        test_image = caffe.io.load_image(test_folder+ images_list[j])\n",
    "        net.blobs['data'].data[i] = transformer.preprocess('data', test_image)\n",
    "        i = i + 1\n",
    "        j = j + 1\n",
    "\n",
    "    out = net.forward()\n",
    "    i=0\n",
    "    while k < num_images and i < BatchSize:\n",
    "        pic = Image.open(test_folder+images_list[k])\n",
    "        A = np.array(pic,dtype='f4')\n",
    "        A = A.transpose((2,0,1))\n",
    "        image_data.append(A)\n",
    "        a = out['fc8_a'][i]\n",
    "        b =  sorted(range(len(a)), key=lambda x: a[x])[-20:]\n",
    "        d = [0] * 106\n",
    "        D= np.array(d)\n",
    "        D[b] = 1\n",
    "        attributes.append(D)\n",
    "        label.append(int(item.split('_')[0]))\n",
    "        i = i + 1\n",
    "        k = k + 1\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "print \"******************************************\"\n",
    "print \"Forward Pass Completed for all Test Images : 2\"\n",
    "print \"******************************************\"\n",
    "label = np.array(label,dtype='f4')\n",
    "attributes = np.array(attributes,dtype='f4')\n",
    "h = h5py.File(\"/users/gpu/agjayant/Market-1501-v15.09.15/market_training2.h5\", 'w' )\n",
    "dset1 = h.create_dataset(\"data\", data=image_data)\n",
    "dset2 = h.create_dataset(\"attributes\", data=attributes)\n",
    "dset3 = h.create_dataset(\"label\",  data=label)\n",
    "h.close()\n",
    "\n",
    "print \"**************************************************\"\n",
    "print \"Saved for all Images: Part 2\"\n",
    "print \"**************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "label = []\n",
    "attributes = []\n",
    "while j < num_images:\n",
    "    net = caffe.Net(sys.argv[1], # deploy prototxt,\n",
    "                sys.argv[2], # model,\n",
    "                caffe.TEST)# input preprocessing: 'data'is the name of the input blob == net.inputs[0]\n",
    "\n",
    "\n",
    "    # set net to batch size\n",
    "    net.blobs['data'].reshape(BatchSize,3,227,227)\n",
    "    i = 0\n",
    "    k = j\n",
    "    while j < num_images and i < BatchSize:\n",
    "        test_image = caffe.io.load_image(test_folder+ images_list[j])\n",
    "        net.blobs['data'].data[i] = transformer.preprocess('data', test_image)\n",
    "        i = i + 1\n",
    "        j = j + 1\n",
    "\n",
    "    out = net.forward()\n",
    "    i=0\n",
    "    while k < num_images and i < BatchSize:\n",
    "        pic = Image.open(test_folder+images_list[k])\n",
    "        A = np.array(pic,dtype='f4')\n",
    "        A = A.transpose((2,0,1))\n",
    "        image_data.append(A)\n",
    "        a = out['fc8_a'][i]\n",
    "        b =  sorted(range(len(a)), key=lambda x: a[x])[-20:]\n",
    "        d = [0] * 106\n",
    "        D= np.array(d)\n",
    "        D[b] = 1\n",
    "        attributes.append(D)\n",
    "        label.append(int(item.split('_')[0]))\n",
    "        i = i + 1\n",
    "        k = k + 1\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "print \"******************************************\"\n",
    "print \"Forward Pass Completed for all Test Images:3\"\n",
    "print \"******************************************\"\n",
    "label = np.array(label,dtype='f4')\n",
    "attributes = np.array(attributes,dtype='f4')\n",
    "h = h5py.File(\"/users/gpu/agjayant/Market-1501-v15.09.15/market_training3.h5\", 'w' )\n",
    "dset1 = h.create_dataset(\"data\", data=image_data)\n",
    "dset2 = h.create_dataset(\"attributes\", data=attributes)\n",
    "dset3 = h.create_dataset(\"label\",  data=label)\n",
    "h.close()\n",
    "\n",
    "print \"**************************************************\"\n",
    "print \"Saved for all Images: Part 3\"\n",
    "print \"**************************************************\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
